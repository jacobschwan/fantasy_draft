---
title: "Scraping Fantrax"
output: html_notebook
---

```{r}
pacman::p_load(tidyverse)
```


Fantrax offers 10 years of player stats along with preseason projections.  Their site is rendered via javascript, but
offers the ability to download player stats as CSV file.  Below is an example link to pull a CSV for the first week of
games in 2017:

>   https://www.fantrax.com/fxpa/downloadPlayerStats?leagueId=vbt60a7tjjwzjtxa&positionOrGroup=FOOTBALL_OFFENSE&seasonOrProjection=SEASON_50k_BY_DATE&timeframeTypeCode=BY_DATE&statusOrTeamFilter=ALL_AVAILABLE&scoringCategoryType=5&timeStartType=PERIOD_ONLY&pageNumber=1&schedulePageAdj=0&startDate=2017-08-29&endDate=2017-09-03&searchName=&txs=false&teamId=ojolt2upjjxmu6b1

The goal is to download week by week player stats for at least the last 5 years. To do this we'll need to manipluate the
above URL and use something like curl to download and name each resulting CSV file.  Let's look at the possible variables.

**leagueID**
**positionOrGroup**
**seasonOrProjection**
**timeframeTypeCode**
**statusOrTeamFilter**
**scoringCategoryType**
**timeStartType**
**pageNumber**
**schedulePageAdj**
**startDate**
**endDate**
**searchName**
**txs**
**teamID**

To start, we'll focus on positionOrGroup, seasonOrProjection, startDate, & endDate.

```{r}
positionOrGroup <- c("FOOTBALL_OFFENSE", "FOOTBALL_DEFENSE", "FOOTBALL_TEAM_DEFENSE_SPECIAL_TEAMS")
seasonOrProjection <- data_frame(year = seq(from = 2017, to = 2007, by = -1),
                                 code = c("SEASON_50k_BY_DATE",
                                          "SEASON_50j_BY_DATE",
                                          "SEASON_50i_BY_DATE",
                                          "SEASON_50h_BY_DATE",
                                          "SEASON_50g_BY_DATE",
                                          "SEASON_50f_BY_DATE",
                                          "SEASON_50e_BY_DATE",
                                          "SEASON_50d_BY_DATE",
                                          "SEASON_50c_BY_DATE",
                                          "SEASON_50a_BY_DATE",
                                          "SEASON_508_BY_DATE"))
```

For start and end date, we'll need to calculate each regualr season week for each year.  There are 13 weeks in the 
regular season, starting with the week before labor day (generally the last week of August).
Each week will run from Tuesday to the following Monday.  We'll need to start by determining the last Tuesday in August 
for a given year.

```{r}
pacman::p_load(lubridate)

#Set year
year <- 2014

#Find last day of August

end_of_aug <- ymd(paste(year,"08","31", sep = "-"))

#Find the Tuesday nearest the last day of August

week_1_start <- floor_date(end_of_aug, "week") + days(2)

#If 8/31 is on a Sunday, our week_1_start will end up after Labor Day (the first Monday of September). We can adjust as
#follows

if(wday(end_of_aug) == 1) {
    week_1_start = week_1_start - days(7)
}

week_1_start
wday(week_1_start, label = T)
```

Let's turn the above code into a function

```{r}
season_start <- function(year) {
    require(lubridate)
    
    #Find last day of August

    end_of_aug <- ymd(paste(year,"08","31", sep = "-"))

    #Find the Tuesday nearest the last day of August

    week_1_start <- floor_date(end_of_aug, "week") + days(2)
    
    #Adjust for 8/31 on a Sunday
    
    if(wday(end_of_aug) == 1) {
       week_1_start = week_1_start - days(7)
    }
    
    return(week_1_start)
}

season_start(2018)
season_start(2014)
```

We can now build a data frame with the start and end date of each week for each year. We'll use seq.Date to set the week
start dates.

```{r}
seq.Date(from = season_start(2018), to = season_start(2018) + weeks(12), by = "week")
```

```{r}
build_season <- function(year) {
    require(lubridate, dplyr)
    
    season <- data_frame(start_date = seq.Date(from = season_start(year),
                                               to = season_start(year) + weeks(12),
                                               by = "week")) %>%
        mutate(end_date = start_date + days(6),
               week_no = row_number(),
               year = year)
    
    return(season)
}

build_season(2018)
```

```{r}
all_seasons <- map_df(seasonOrProjection$year, build_season)
all_seasons
```

```{r}
seasonOrProjection %>%
    left_join(all_seasons, by = c("year"))
```

Test downloading CSV files

```{r}
pacman::p_load(curl)
```


```{r}
curl::curl_download(url = "https://www.fantrax.com/fxpa/downloadPlayerStats?leagueId=vbt60a7tjjwzjtxa&positionOrGroup=FOOTBALL_OFFENSE&seasonOrProjection=SEASON_50k_BY_DATE&timeframeTypeCode=BY_DATE&statusOrTeamFilter=ALL_AVAILABLE&scoringCategoryType=5&timeStartType=PERIOD_ONLY&pageNumber=1&schedulePageAdj=0&startDate=2017-08-29&endDate=2017-09-03&searchName=&txs=false&teamId=ojolt2upjjxmu6b1",
                    destfile = "test.csv")
```

This failed because we were not logged into the website.

To get around this, we'll log into Fantrax and then copy the cookie information into a curl handle.  Googling revealed 
this curl command from Github user daveberman:

Code from Github daveberman/fantrax-scraper

>curl "http://www.fantrax.com/" 

>     -H "Accept-Encoding: gzip, deflate, sdch" 

>     -H "Accept-Language: en-US,en;q=0.8" 

>     -H "User-Agent: Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.65 
Safari/537.36" 

>     -H "Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8" 

>     -H "Cache-Control: max-age=0" 

>     -H "Cookie: uig=acgtszvii7e3wdjc; uac=ycza5clii7e3wdjd; ui=pa5y4yk7i74tcfyh; BAYEUX_BROWSER=9cf0-15gjjos4eant8i7kppbjpv00; __utmt=1; __utma=221131663.1812537929.1426645516.1432428782.1432432096.161; __utmb=221131663.19.10.1432432096; __utmc=221131663; __utmz=221131663.1426645516.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none); JSESSIONID=1ap4v6rc8c9g4o0qxvtzocgz4; FANTRAX_REMEMBERS=""ZGJiODE3OjE3NDc3OTQ0NTk1NDk6MzExMjZiZTQxNjRiNGM1NjM4M2ZiY2U5MWQ3YTc1NzM=""" 

>    -H "Connection: keep-alive" --compressed


We'll load in the cookie infromation with the fantrax specfic element from our cookie.

```{r}
fantrax_handle <- new_handle()
handle_setheaders(fantrax_handle,
                  "Accept-Encoding" = "gzip, deflate, sdch",
                  "Accept-Language" = "en-Us,en;q=0.8",
                  "User_Agent" = "Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.65 Safari/537.36",
                  "Accept" = "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
                  "Cache-Control" = "max-age=0",
                  "Connection" = "keep-alive",
                  "Cookie" = 'uig=cgy86l6tjl3rqi4h; uac=10n79abojl3rqi4h; ui=wjy9qxvijjz4kho0; BAYEUX_BROWSER=abxcgtep2w1jr6bq;JSESSIONID=node0lvyebaf8egfi1qw3aufto92tk9809.node0; FX_REM=anNjaHdhbjoxODUwMjM1NzI5NDM5OjMzMjM1NmYzMWQ4YjdmNGM0N2Y3NzgxNTYzZDY5NTFk; _ga=GA1.2.1427721507.1534859530; _gid=GA1.2.1623411655.1534859530')
```


```{r}
curl_download(url = "https://www.fantrax.com/fxpa/downloadPlayerStats?leagueId=vbt60a7tjjwzjtxa&positionOrGroup=FOOTBALL_OFFENSE&seasonOrProjection=SEASON_50k_BY_DATE&timeframeTypeCode=BY_DATE&statusOrTeamFilter=ALL_AVAILABLE&scoringCategoryType=5&timeStartType=PERIOD_ONLY&pageNumber=1&schedulePageAdj=0&startDate=2017-08-29&endDate=2017-09-03&searchName=&txs=false&teamId=ojolt2upjjxmu6b1",
                    destfile = "test.csv",
              handle = fantrax_handle)
```

Success!

```{r}
res <- curl_fetch_memory(url = "https://www.fantrax.com/fxpa/downloadPlayerStats?leagueId=vbt60a7tjjwzjtxa&positionOrGroup=FOOTBALL_OFFENSE&seasonOrProjection=SEASON_50k_BY_DATE&timeframeTypeCode=BY_DATE&statusOrTeamFilter=ALL_AVAILABLE&scoringCategoryType=5&timeStartType=PERIOD_ONLY&pageNumber=1&schedulePageAdj=0&startDate=2017-08-29&endDate=2017-09-03&searchName=&txs=false&teamId=ojolt2upjjxmu6b1", handle = fantrax_handle)

rawToChar(res$content) %>%
    read_csv()
```

```{r}
curl_fetch_memory(url = "https://www.fantrax.com/fxpa/downloadPlayerStats?leagueId=vbt60a7tjjwzjtxa&positionOrGroup=FOOTBALL_OFFENSE&seasonOrProjection=SEASON_50k_BY_DATE&timeframeTypeCode=BY_DATE&statusOrTeamFilter=ALL_AVAILABLE&scoringCategoryType=5&timeStartType=PERIOD_ONLY&pageNumber=1&schedulePageAdj=0&startDate=2017-08-29&endDate=2017-09-03&searchName=&txs=false&teamId=ojolt2upjjxmu6b1", handle = fantrax_handle)$content %>%
    rawToChar() %>%
    read_csv()
```


Now let's setup a dataframe will all our combinations for scraping.

```{r}
all_codes <- seasonOrProjection %>%
    left_join(all_seasons, by = c("year"))

all_groups <- map_df(positionOrGroup, function(x, df){mutate(df, group = x)}, df = all_codes)
```

And our single combination scraping function

```{r}
scrape_fantrax <- function(year, code, start_date, end_date, week_no, group, handle) {
    require(glue, dplyr, curl, readr)
    dest_file <- file.path(here::here("data"), glue("Fantrax-players-{year}-week-{week_no}-{group}.csv"))
    dl_url <- glue("https://www.fantrax.com/fxpa/downloadPlayerStats?leagueId=vbt60a7tjjwzjtxa&positionOrGroup={group}&","seasonOrProjection={code}&timeframeTypeCode=BY_DATE&statusOrTeamFilter=ALL_AVAILABLE&scoringCategoryType=5&timeStartType=PERIOD_ONLY&pageNumber=1&schedulePageAdj=0&startDate={start_date}&endDate={end_date}&searchName=&txs=false&teamId=ojolt2upjjxmu6b1")
    curl_download(url = dl_url,
                  destfile = dest_file,
                  handle = handle)
}
```

```{r, eval = F}
all_groups %>%
    pwalk(scrape_fantrax, handle = fantrax_handle)
```

walk seems to fail, even with sleep function. Looks like we'll need to batch

Let's try an alternative...
```{r}
all_filenames <- all_groups %>% 
    mutate(dest_file = file.path(here::here("data"), glue::glue("Fantrax-players-{year}-week-{week_no}-{group}.csv")))
```

```{r}
file.exists(all_filenames$dest_file)
```

```{r}
scrape_fantrax_2 <- function(year, code, start_date, end_date, week_no, group, dest_file, handle) {
#    require(glue, dplyr, curl, readr)
    dl_url <- glue::glue("https://www.fantrax.com/fxpa/downloadPlayerStats?leagueId=vbt60a7tjjwzjtxa&positionOrGroup={group}&","seasonOrProjection={code}&timeframeTypeCode=BY_DATE&statusOrTeamFilter=ALL_AVAILABLE&scoringCategoryType=5&timeStartType=PERIOD_ONLY&pageNumber=1&schedulePageAdj=0&startDate={start_date}&endDate={end_date}&searchName=&txs=false&teamId=ojolt2upjjxmu6b1")
    curl::curl_download(url = dl_url,
                  destfile = dest_file,
                  handle = handle)
    print(paste(year, week_no, dest_file))
}

while (sum(!file.exists(all_filenames$dest_file)) != 0) {
     tryCatch(all_filenames %>%
         filter(!(file.exists(all_filenames$dest_file))) %>%
         pwalk(scrape_fantrax_2, handle = fantrax_handle),
         error=function(e){Sys.sleep(5)})
}
```


